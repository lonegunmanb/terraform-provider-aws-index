package github.com/hashicorp/terraform-provider-aws/internal/service/lambda
import (
	"context"
	"errors"
	"log"
	"slices"
	"strings"
	"time"

	"github.com/YakDriver/regexache"
	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/aws/arn"
	"github.com/aws/aws-sdk-go-v2/service/lambda"
	awstypes "github.com/aws/aws-sdk-go-v2/service/lambda/types"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	"github.com/hashicorp/terraform-provider-aws/internal/conns"
	"github.com/hashicorp/terraform-provider-aws/internal/enum"
	"github.com/hashicorp/terraform-provider-aws/internal/errs"
	"github.com/hashicorp/terraform-provider-aws/internal/errs/sdkdiag"
	"github.com/hashicorp/terraform-provider-aws/internal/flex"
	"github.com/hashicorp/terraform-provider-aws/internal/retry"
	tftags "github.com/hashicorp/terraform-provider-aws/internal/tags"
	"github.com/hashicorp/terraform-provider-aws/internal/tfresource"
	inttypes "github.com/hashicorp/terraform-provider-aws/internal/types"
	"github.com/hashicorp/terraform-provider-aws/internal/verify"
	"github.com/hashicorp/terraform-provider-aws/names"
)
func resourceEventSourceMappingUpdate(ctx context.Context, d *schema.ResourceData, meta any) diag.Diagnostics {
	var diags diag.Diagnostics
	conn := meta.(*conns.AWSClient).LambdaClient(ctx)

	if d.HasChangesExcept(names.AttrTags, names.AttrTagsAll) {
		input := lambda.UpdateEventSourceMappingInput{
			UUID: aws.String(d.Id()),
		}

		if d.HasChange("batch_size") {
			input.BatchSize = aws.Int32(int32(d.Get("batch_size").(int)))
		}

		if d.HasChange("bisect_batch_on_function_error") {
			input.BisectBatchOnFunctionError = aws.Bool(d.Get("bisect_batch_on_function_error").(bool))
		}

		if d.HasChange("destination_config") {
			if v, ok := d.GetOk("destination_config"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.DestinationConfig = expandDestinationConfig(v.([]any)[0].(map[string]any))
			}
		}

		if d.HasChange("document_db_event_source_config") {
			if v, ok := d.GetOk("document_db_event_source_config"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.DocumentDBEventSourceConfig = expandDocumentDBEventSourceConfig(v.([]any)[0].(map[string]any))
			}
		}

		if d.HasChange(names.AttrEnabled) {
			input.Enabled = aws.Bool(d.Get(names.AttrEnabled).(bool))
		}

		if d.HasChange("filter_criteria") {
			if v, ok := d.GetOk("filter_criteria"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.FilterCriteria = expandFilterCriteria(v.([]any)[0].(map[string]any))
			} else {
				// AWS ignores the removal if this is left as nil.
				input.FilterCriteria = &awstypes.FilterCriteria{}
			}
		}

		if d.HasChange("function_name") {
			input.FunctionName = aws.String(d.Get("function_name").(string))
		}

		if d.HasChange("function_response_types") {
			input.FunctionResponseTypes = flex.ExpandStringyValueSet[awstypes.FunctionResponseType](d.Get("function_response_types").(*schema.Set))
		}

		if d.HasChange(names.AttrKMSKeyARN) {
			input.KMSKeyArn = aws.String(d.Get(names.AttrKMSKeyARN).(string))
		}

		if d.HasChange("maximum_batching_window_in_seconds") {
			input.MaximumBatchingWindowInSeconds = aws.Int32(int32(d.Get("maximum_batching_window_in_seconds").(int)))
		}

		if d.HasChange("maximum_record_age_in_seconds") {
			input.MaximumRecordAgeInSeconds = aws.Int32(int32(d.Get("maximum_record_age_in_seconds").(int)))
		}

		if d.HasChange("maximum_retry_attempts") {
			input.MaximumRetryAttempts = aws.Int32(int32(d.Get("maximum_retry_attempts").(int)))
		}

		if d.HasChange("metrics_config") {
			if v, ok := d.GetOk("metrics_config"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.MetricsConfig = expandEventSourceMappingMetricsConfig((v.([]any)[0].(map[string]any)))
			} else {
				input.MetricsConfig = &awstypes.EventSourceMappingMetricsConfig{}
			}
		}

		if d.HasChange("parallelization_factor") {
			input.ParallelizationFactor = aws.Int32(int32(d.Get("parallelization_factor").(int)))
		}

		if d.HasChange("provisioned_poller_config") {
			if v, ok := d.GetOk("provisioned_poller_config"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.ProvisionedPollerConfig = expandProvisionedPollerConfig(v.([]any)[0].(map[string]any))
			} else {
				// AWS ignores the removal if this is left as nil.
				input.ProvisionedPollerConfig = &awstypes.ProvisionedPollerConfig{}
			}
		}

		if d.HasChange("scaling_config") {
			if v, ok := d.GetOk("scaling_config"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.ScalingConfig = expandScalingConfig(v.([]any)[0].(map[string]any))
			} else {
				// AWS ignores the removal if this is left as nil.
				input.ScalingConfig = &awstypes.ScalingConfig{}
			}
		}

		if d.HasChange("source_access_configuration") {
			if v, ok := d.GetOk("source_access_configuration"); ok && v.(*schema.Set).Len() > 0 {
				input.SourceAccessConfigurations = expandSourceAccessConfigurations(v.(*schema.Set).List())
			}
		}

		if d.HasChange("tumbling_window_in_seconds") {
			input.TumblingWindowInSeconds = aws.Int32(int32(d.Get("tumbling_window_in_seconds").(int)))
		}

		_, err := retryEventSourceMapping(ctx, func(ctx context.Context) (*lambda.UpdateEventSourceMappingOutput, error) {
			return conn.UpdateEventSourceMapping(ctx, &input)
		})

		if err != nil {
			return sdkdiag.AppendErrorf(diags, "updating Lambda Event Source Mapping (%s): %s", d.Id(), err)
		}

		if _, err := waitEventSourceMappingUpdated(ctx, conn, d.Id()); err != nil {
			return sdkdiag.AppendErrorf(diags, "waiting for Lambda Event Source Mapping (%s) update: %s", d.Id(), err)
		}
	}

	return append(diags, resourceEventSourceMappingRead(ctx, d, meta)...)
}
