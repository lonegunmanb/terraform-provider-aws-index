package github.com/hashicorp/terraform-provider-aws/internal/service/datasync
import (
	"context"
	"log"
	"strings"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/service/datasync"
	awstypes "github.com/aws/aws-sdk-go-v2/service/datasync/types"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	sdkretry "github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	"github.com/hashicorp/terraform-provider-aws/internal/conns"
	"github.com/hashicorp/terraform-provider-aws/internal/enum"
	"github.com/hashicorp/terraform-provider-aws/internal/errs"
	"github.com/hashicorp/terraform-provider-aws/internal/errs/sdkdiag"
	"github.com/hashicorp/terraform-provider-aws/internal/flex"
	"github.com/hashicorp/terraform-provider-aws/internal/retry"
	tftags "github.com/hashicorp/terraform-provider-aws/internal/tags"
	"github.com/hashicorp/terraform-provider-aws/internal/tfresource"
	inttypes "github.com/hashicorp/terraform-provider-aws/internal/types"
	"github.com/hashicorp/terraform-provider-aws/internal/verify"
	"github.com/hashicorp/terraform-provider-aws/names"
)
func resourceLocationHDFSUpdate(ctx context.Context, d *schema.ResourceData, meta any) diag.Diagnostics {
	var diags diag.Diagnostics
	conn := meta.(*conns.AWSClient).DataSyncClient(ctx)

	if d.HasChangesExcept(names.AttrTags, names.AttrTagsAll) {
		input := &datasync.UpdateLocationHdfsInput{
			LocationArn: aws.String(d.Id()),
		}

		if d.HasChange("agent_arns") {
			input.AgentArns = flex.ExpandStringValueSet(d.Get("agent_arns").(*schema.Set))
		}

		if d.HasChange("authentication_type") {
			input.AuthenticationType = awstypes.HdfsAuthenticationType(d.Get("authentication_type").(string))
		}

		if d.HasChange("block_size") {
			input.BlockSize = aws.Int32(int32(d.Get("block_size").(int)))
		}

		if d.HasChanges("kerberos_keytab", "kerberos_keytab_base64") {
			if v, ok := d.GetOk("kerberos_keytab"); ok {
				input.KerberosKeytab = []byte(v.(string))
			} else if v, ok := d.GetOk("kerberos_keytab_base64"); ok {
				v := v.(string)
				b, err := inttypes.Base64Decode(v)
				if err != nil {
					b = []byte(v)
				}
				input.KerberosKeytab = b
			}
		}

		if d.HasChanges("kerberos_krb5_conf", "kerberos_krb5_conf_base64") {
			if v, ok := d.GetOk("kerberos_krb5_conf"); ok {
				input.KerberosKrb5Conf = []byte(v.(string))
			} else if v, ok := d.GetOk("kerberos_krb5_conf_base64"); ok {
				v := v.(string)
				b, err := inttypes.Base64Decode(v)
				if err != nil {
					b = []byte(v)
				}
				input.KerberosKrb5Conf = b
			}
		}

		if d.HasChange("kerberos_principal") {
			input.KerberosPrincipal = aws.String(d.Get("kerberos_principal").(string))
		}

		if d.HasChange("kms_key_provider_uri") {
			input.KmsKeyProviderUri = aws.String(d.Get("kms_key_provider_uri").(string))
		}

		if d.HasChange("name_node") {
			input.NameNodes = expandHDFSNameNodes(d.Get("name_node").(*schema.Set))
		}

		if d.HasChange("qop_configuration") {
			input.QopConfiguration = expandHDFSQOPConfiguration(d.Get("qop_configuration").([]any))
		}

		if d.HasChange("replication_factor") {
			input.ReplicationFactor = aws.Int32(int32(d.Get("replication_factor").(int)))
		}

		if d.HasChange("simple_user") {
			input.SimpleUser = aws.String(d.Get("simple_user").(string))
		}

		if d.HasChange("subdirectory") {
			input.Subdirectory = aws.String(d.Get("subdirectory").(string))
		}

		_, err := conn.UpdateLocationHdfs(ctx, input)

		if err != nil {
			return sdkdiag.AppendErrorf(diags, "updating DataSync Location HDFS (%s): %s", d.Id(), err)
		}
	}

	return append(diags, resourceLocationHDFSRead(ctx, d, meta)...)
}
