package github.com/hashicorp/terraform-provider-aws/internal/service/glue
import (
	"context"
	"fmt"
	"log"
	"strings"

	"github.com/YakDriver/regexache"
	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/aws/arn"
	"github.com/aws/aws-sdk-go-v2/service/glue"
	awstypes "github.com/aws/aws-sdk-go-v2/service/glue/types"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/structure"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	"github.com/hashicorp/terraform-provider-aws/internal/conns"
	"github.com/hashicorp/terraform-provider-aws/internal/enum"
	"github.com/hashicorp/terraform-provider-aws/internal/errs"
	"github.com/hashicorp/terraform-provider-aws/internal/errs/sdkdiag"
	"github.com/hashicorp/terraform-provider-aws/internal/flex"
	tftags "github.com/hashicorp/terraform-provider-aws/internal/tags"
	"github.com/hashicorp/terraform-provider-aws/internal/tfresource"
	"github.com/hashicorp/terraform-provider-aws/internal/verify"
	"github.com/hashicorp/terraform-provider-aws/names"
)
func resourceCrawlerRead(ctx context.Context, d *schema.ResourceData, meta any) diag.Diagnostics {
	var diags diag.Diagnostics
	conn := meta.(*conns.AWSClient).GlueClient(ctx)

	crawler, err := findCrawlerByName(ctx, conn, d.Id())
	if !d.IsNewResource() && tfresource.NotFound(err) {
		log.Printf("[WARN] Glue Crawler (%s) not found, removing from state", d.Id())
		d.SetId("")
		return diags
	}

	if err != nil {
		return sdkdiag.AppendErrorf(diags, "reading Glue Crawler (%s): %s", d.Id(), err)
	}

	crawlerARN := arn.ARN{
		Partition: meta.(*conns.AWSClient).Partition(ctx),
		Service:   "glue",
		Region:    meta.(*conns.AWSClient).Region(ctx),
		AccountID: meta.(*conns.AWSClient).AccountID(ctx),
		Resource:  fmt.Sprintf("crawler/%s", d.Id()),
	}.String()
	d.Set(names.AttrARN, crawlerARN)
	d.Set(names.AttrName, crawler.Name)
	d.Set(names.AttrDatabaseName, crawler.DatabaseName)
	d.Set(names.AttrRole, crawler.Role)
	d.Set(names.AttrConfiguration, crawler.Configuration)
	d.Set(names.AttrDescription, crawler.Description)
	d.Set("security_configuration", crawler.CrawlerSecurityConfiguration)
	d.Set(names.AttrSchedule, "")
	if crawler.Schedule != nil {
		d.Set(names.AttrSchedule, crawler.Schedule.ScheduleExpression)
	}
	if err := d.Set("classifiers", flex.FlattenStringValueList(crawler.Classifiers)); err != nil {
		return sdkdiag.AppendErrorf(diags, "setting classifiers: %s", err)
	}
	d.Set("table_prefix", crawler.TablePrefix)

	if crawler.SchemaChangePolicy != nil {
		if err := d.Set("schema_change_policy", flattenCrawlerSchemaChangePolicy(crawler.SchemaChangePolicy)); err != nil {
			return sdkdiag.AppendErrorf(diags, "setting schema_change_policy: %s", err)
		}
	}

	if crawler.Targets != nil {
		if err := d.Set("dynamodb_target", flattenDynamoDBTargets(crawler.Targets.DynamoDBTargets)); err != nil {
			return sdkdiag.AppendErrorf(diags, "setting dynamodb_target: %s", err)
		}

		if err := d.Set("jdbc_target", flattenJDBCTargets(crawler.Targets.JdbcTargets)); err != nil {
			return sdkdiag.AppendErrorf(diags, "setting jdbc_target: %s", err)
		}

		if err := d.Set("s3_target", flattenS3Targets(crawler.Targets.S3Targets)); err != nil {
			return sdkdiag.AppendErrorf(diags, "setting s3_target: %s", err)
		}

		if err := d.Set("catalog_target", flattenCatalogTargets(crawler.Targets.CatalogTargets)); err != nil {
			return sdkdiag.AppendErrorf(diags, "setting catalog_target: %s", err)
		}

		if err := d.Set("mongodb_target", flattenMongoDBTargets(crawler.Targets.MongoDBTargets)); err != nil {
			return sdkdiag.AppendErrorf(diags, "setting mongodb_target: %s", err)
		}

		if err := d.Set("delta_target", flattenDeltaTargets(crawler.Targets.DeltaTargets)); err != nil {
			return sdkdiag.AppendErrorf(diags, "setting delta_target: %s", err)
		}

		if err := d.Set("hudi_target", flattenHudiTargets(crawler.Targets.HudiTargets)); err != nil {
			return sdkdiag.AppendErrorf(diags, "setting hudi_target: %s", err)
		}

		if err := d.Set("iceberg_target", flattenIcebergTargets(crawler.Targets.IcebergTargets)); err != nil {
			return sdkdiag.AppendErrorf(diags, "setting iceberg_target: %s", err)
		}
	}

	if err := d.Set("lineage_configuration", flattenCrawlerLineageConfiguration(crawler.LineageConfiguration)); err != nil {
		return sdkdiag.AppendErrorf(diags, "setting lineage_configuration: %s", err)
	}

	if err := d.Set("lake_formation_configuration", flattenLakeFormationConfiguration(crawler.LakeFormationConfiguration)); err != nil {
		return sdkdiag.AppendErrorf(diags, "setting lake_formation_configuration: %s", err)
	}

	if err := d.Set("recrawl_policy", flattenCrawlerRecrawlPolicy(crawler.RecrawlPolicy)); err != nil {
		return sdkdiag.AppendErrorf(diags, "setting recrawl_policy: %s", err)
	}

	return diags
}
