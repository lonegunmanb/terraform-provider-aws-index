package github.com/hashicorp/terraform-provider-aws/internal/service/firehose
import (
	"context"
	"fmt"
	"log"
	"slices"
	"strings"
	"time"

	"github.com/YakDriver/regexache"
	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/aws/arn"
	"github.com/aws/aws-sdk-go-v2/service/firehose"
	"github.com/aws/aws-sdk-go-v2/service/firehose/types"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/customdiff"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	"github.com/hashicorp/terraform-provider-aws/internal/conns"
	"github.com/hashicorp/terraform-provider-aws/internal/enum"
	"github.com/hashicorp/terraform-provider-aws/internal/errs"
	"github.com/hashicorp/terraform-provider-aws/internal/errs/sdkdiag"
	"github.com/hashicorp/terraform-provider-aws/internal/flex"
	tftags "github.com/hashicorp/terraform-provider-aws/internal/tags"
	"github.com/hashicorp/terraform-provider-aws/internal/tfresource"
	"github.com/hashicorp/terraform-provider-aws/internal/verify"
	"github.com/hashicorp/terraform-provider-aws/names"
)
func resourceDeliveryStreamUpdate(ctx context.Context, d *schema.ResourceData, meta any) diag.Diagnostics {
	var diags diag.Diagnostics
	conn := meta.(*conns.AWSClient).FirehoseClient(ctx)

	sn := d.Get(names.AttrName).(string)

	if d.HasChangesExcept(names.AttrTags, names.AttrTagsAll) {
		input := &firehose.UpdateDestinationInput{
			CurrentDeliveryStreamVersionId: aws.String(d.Get("version_id").(string)),
			DeliveryStreamName:             aws.String(sn),
			DestinationId:                  aws.String(d.Get("destination_id").(string)),
		}

		switch v := destinationType(d.Get(names.AttrDestination).(string)); v {
		case destinationTypeElasticsearch:
			if v, ok := d.GetOk("elasticsearch_configuration"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.ElasticsearchDestinationUpdate = expandElasticsearchDestinationUpdate(v.([]any)[0].(map[string]any))
			}
		case destinationTypeExtendedS3:
			if v, ok := d.GetOk("extended_s3_configuration"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.ExtendedS3DestinationUpdate = expandExtendedS3DestinationUpdate(v.([]any)[0].(map[string]any))
			}
		case destinationTypeHTTPEndpoint:
			if v, ok := d.GetOk("http_endpoint_configuration"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.HttpEndpointDestinationUpdate = expandHTTPEndpointDestinationUpdate(v.([]any)[0].(map[string]any))
			}
		case destinationTypeIceberg:
			if v, ok := d.GetOk("iceberg_configuration"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.IcebergDestinationUpdate = expandIcebergDestinationUpdate(v.([]any)[0].(map[string]any))
			}
		case destinationTypeOpenSearch:
			if v, ok := d.GetOk("opensearch_configuration"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.AmazonopensearchserviceDestinationUpdate = expandAmazonopensearchserviceDestinationUpdate(v.([]any)[0].(map[string]any))
			}
		case destinationTypeOpenSearchServerless:
			if v, ok := d.GetOk("opensearchserverless_configuration"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.AmazonOpenSearchServerlessDestinationUpdate = expandAmazonOpenSearchServerlessDestinationUpdate(v.([]any)[0].(map[string]any))
			}
		case destinationTypeRedshift:
			if v, ok := d.GetOk("redshift_configuration"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.RedshiftDestinationUpdate = expandRedshiftDestinationUpdate(v.([]any)[0].(map[string]any))
			}
		case destinationTypeSnowflake:
			if v, ok := d.GetOk("snowflake_configuration"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.SnowflakeDestinationUpdate = expandSnowflakeDestinationUpdate(v.([]any)[0].(map[string]any))
			}
		case destinationTypeSplunk:
			if v, ok := d.GetOk("splunk_configuration"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
				input.SplunkDestinationUpdate = expandSplunkDestinationUpdate(v.([]any)[0].(map[string]any))
			}
		}

		_, err := retryDeliveryStreamOp(ctx, func(ctx context.Context) (any, error) {
			return conn.UpdateDestination(ctx, input)
		})

		if err != nil {
			return sdkdiag.AppendErrorf(diags, "updating Kinesis Firehose Delivery Stream (%s): %s", sn, err)
		}
	}

	if d.HasChange("server_side_encryption") {
		v := d.Get("server_side_encryption")
		if isDeliveryStreamOptionDisabled(v) {
			input := &firehose.StopDeliveryStreamEncryptionInput{
				DeliveryStreamName: aws.String(sn),
			}

			_, err := conn.StopDeliveryStreamEncryption(ctx, input)

			if err != nil {
				return sdkdiag.AppendErrorf(diags, "stopping Kinesis Firehose Delivery Stream (%s) encryption: %s", sn, err)
			}

			if _, err := waitDeliveryStreamEncryptionDisabled(ctx, conn, sn, d.Timeout(schema.TimeoutUpdate)); err != nil {
				return sdkdiag.AppendErrorf(diags, "waiting for Kinesis Firehose Delivery Stream (%s) encryption disable: %s", sn, err)
			}
		} else {
			input := &firehose.StartDeliveryStreamEncryptionInput{
				DeliveryStreamEncryptionConfigurationInput: expandDeliveryStreamEncryptionConfigurationInput(v.([]any)),
				DeliveryStreamName:                         aws.String(sn),
			}

			_, err := conn.StartDeliveryStreamEncryption(ctx, input)

			if err != nil {
				return sdkdiag.AppendErrorf(diags, "starting Kinesis Firehose Delivery Stream (%s) encryption: %s", sn, err)
			}

			if _, err := waitDeliveryStreamEncryptionEnabled(ctx, conn, sn, d.Timeout(schema.TimeoutUpdate)); err != nil {
				return sdkdiag.AppendErrorf(diags, "waiting for Kinesis Firehose Delivery Stream (%s) encryption enable: %s", sn, err)
			}
		}
	}

	return append(diags, resourceDeliveryStreamRead(ctx, d, meta)...)
}
