package github.com/hashicorp/terraform-provider-aws/internal/service/kinesis
import (
	"context"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/service/kinesis"
	"github.com/aws/aws-sdk-go-v2/service/kinesis/types"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-provider-aws/internal/conns"
	"github.com/hashicorp/terraform-provider-aws/internal/errs/sdkdiag"
	tftags "github.com/hashicorp/terraform-provider-aws/internal/tags"
	"github.com/hashicorp/terraform-provider-aws/names"
)
func dataSourceStreamRead(ctx context.Context, d *schema.ResourceData, meta any) diag.Diagnostics {
	var diags diag.Diagnostics
	conn := meta.(*conns.AWSClient).KinesisClient(ctx)

	name := d.Get(names.AttrName).(string)
	stream, err := findStreamByName(ctx, conn, name)

	if err != nil {
		return sdkdiag.AppendErrorf(diags, "reading Kinesis Stream (%s): %s", name, err)
	}

	input := kinesis.ListShardsInput{
		StreamName: aws.String(name),
	}
	var shards []types.Shard

	err = listShardsPages(ctx, conn, &input, func(page *kinesis.ListShardsOutput, lastPage bool) bool {
		shards = append(shards, page.Shards...)
		return !lastPage
	})

	if err != nil {
		return sdkdiag.AppendErrorf(diags, "listing Kinesis Stream (%s) shards: %s", name, err)
	}

	// See http://docs.aws.amazon.com/kinesis/latest/dev/kinesis-using-sdk-java-resharding-merge.html.
	var openShards, closedShards []*string
	for _, shard := range shards {
		if shard.SequenceNumberRange.EndingSequenceNumber == nil {
			openShards = append(openShards, shard.ShardId)
		} else {
			closedShards = append(closedShards, shard.ShardId)
		}
	}

	d.SetId(aws.ToString(stream.StreamARN))
	d.Set(names.AttrARN, stream.StreamARN)
	d.Set("closed_shards", aws.ToStringSlice(closedShards))
	d.Set("creation_timestamp", aws.ToTime(stream.StreamCreationTimestamp).Unix())
	d.Set("encryption_type", stream.EncryptionType)
	d.Set(names.AttrKMSKeyID, stream.KeyId)
	d.Set("max_record_size_in_kib", stream.MaxRecordSizeInKiB)
	d.Set(names.AttrName, stream.StreamName)
	d.Set("open_shards", aws.ToStringSlice(openShards))
	d.Set(names.AttrRetentionPeriod, stream.RetentionPeriodHours)
	var shardLevelMetrics []types.MetricsName
	for _, v := range stream.EnhancedMonitoring {
		shardLevelMetrics = append(shardLevelMetrics, v.ShardLevelMetrics...)
	}
	d.Set("shard_level_metrics", shardLevelMetrics)
	d.Set(names.AttrStatus, stream.StreamStatus)
	if details := stream.StreamModeDetails; details != nil {
		if err := d.Set("stream_mode_details", []any{flattenStreamModeDetails(details)}); err != nil {
			return sdkdiag.AppendErrorf(diags, "setting stream_mode_details: %s", err)
		}
	} else {
		d.Set("stream_mode_details", nil)
	}

	return diags
}
