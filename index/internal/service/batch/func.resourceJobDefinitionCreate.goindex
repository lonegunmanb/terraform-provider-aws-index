package github.com/hashicorp/terraform-provider-aws/internal/service/batch
import (
	"context"
	"fmt"
	"log"
	"reflect"
	"strings"

	"github.com/YakDriver/regexache"
	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/service/batch"
	awstypes "github.com/aws/aws-sdk-go-v2/service/batch/types"
	"github.com/hashicorp/go-cty/cty"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/structure"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	"github.com/hashicorp/terraform-provider-aws/internal/conns"
	"github.com/hashicorp/terraform-provider-aws/internal/enum"
	"github.com/hashicorp/terraform-provider-aws/internal/errs"
	"github.com/hashicorp/terraform-provider-aws/internal/errs/sdkdiag"
	"github.com/hashicorp/terraform-provider-aws/internal/flex"
	"github.com/hashicorp/terraform-provider-aws/internal/provider/sdkv2/importer"
	"github.com/hashicorp/terraform-provider-aws/internal/sdkv2"
	tftags "github.com/hashicorp/terraform-provider-aws/internal/tags"
	"github.com/hashicorp/terraform-provider-aws/internal/tfresource"
	"github.com/hashicorp/terraform-provider-aws/names"
)
func resourceJobDefinitionCreate(ctx context.Context, d *schema.ResourceData, meta any) diag.Diagnostics {
	var diags diag.Diagnostics
	conn := meta.(*conns.AWSClient).BatchClient(ctx)

	name := d.Get(names.AttrName).(string)
	jobDefinitionType := awstypes.JobDefinitionType(d.Get(names.AttrType).(string))
	input := &batch.RegisterJobDefinitionInput{
		JobDefinitionName: aws.String(name),
		PropagateTags:     aws.Bool(d.Get(names.AttrPropagateTags).(bool)),
		Tags:              getTagsIn(ctx),
		Type:              jobDefinitionType,
	}

	switch jobDefinitionType {
	case awstypes.JobDefinitionTypeContainer:
		if v, ok := d.GetOk("node_properties"); ok && v != nil {
			return sdkdiag.AppendErrorf(diags, "No `node_properties` can be specified when `type` is %q", jobDefinitionType)
		}

		if v, ok := d.GetOk("container_properties"); ok {
			props, err := expandContainerProperties(v.(string))
			if err != nil {
				return sdkdiag.AppendFromErr(diags, err)
			}

			diags = append(diags, removeEmptyEnvironmentVariables(props.Environment, cty.GetAttrPath("container_properties"))...)
			input.ContainerProperties = props
		}

		if v, ok := d.GetOk("ecs_properties"); ok {
			props, err := expandECSProperties(v.(string))
			if err != nil {
				return sdkdiag.AppendFromErr(diags, err)
			}

			for _, taskProps := range props.TaskProperties {
				for _, container := range taskProps.Containers {
					diags = append(diags, removeEmptyEnvironmentVariables(container.Environment, cty.GetAttrPath("ecs_properties"))...)
				}
			}
			input.EcsProperties = props
		}

		if v, ok := d.GetOk("eks_properties"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
			eksProps := v.([]any)[0].(map[string]any)
			if podProps, ok := eksProps["pod_properties"].([]any); ok && len(podProps) > 0 {
				props := expandEKSPodProperties(podProps[0].(map[string]any))
				input.EksProperties = &awstypes.EksProperties{
					PodProperties: props,
				}
			}
		}

	case awstypes.JobDefinitionTypeMultinode:
		if v, ok := d.GetOk("container_properties"); ok && v != nil {
			return sdkdiag.AppendErrorf(diags, "No `container_properties` can be specified when `type` is %q", jobDefinitionType)
		}
		if v, ok := d.GetOk("ecs_properties"); ok && v != nil {
			return sdkdiag.AppendErrorf(diags, "No `ecs_properties` can be specified when `type` is %q", jobDefinitionType)
		}
		if v, ok := d.GetOk("eks_properties"); ok && v != nil {
			return sdkdiag.AppendErrorf(diags, "No `eks_properties` can be specified when `type` is %q", jobDefinitionType)
		}

		if v, ok := d.GetOk("node_properties"); ok {
			props, err := expandJobNodeProperties(v.(string))
			if err != nil {
				return sdkdiag.AppendFromErr(diags, err)
			}

			for _, node := range props.NodeRangeProperties {
				if node.Container != nil {
					diags = append(diags, removeEmptyEnvironmentVariables(node.Container.Environment, cty.GetAttrPath("node_properties"))...)
				}
			}
			input.NodeProperties = props
		}
	}

	if v, ok := d.GetOk(names.AttrParameters); ok {
		input.Parameters = flex.ExpandStringValueMap(v.(map[string]any))
	}

	if v, ok := d.GetOk("platform_capabilities"); ok && v.(*schema.Set).Len() > 0 {
		input.PlatformCapabilities = flex.ExpandStringyValueSet[awstypes.PlatformCapability](v.(*schema.Set))
	}

	if v, ok := d.GetOk("retry_strategy"); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
		input.RetryStrategy = expandRetryStrategy(v.([]any)[0].(map[string]any))
	}

	if v, ok := d.GetOk("scheduling_priority"); ok {
		input.SchedulingPriority = aws.Int32(int32(v.(int)))
	}

	if v, ok := d.GetOk(names.AttrTimeout); ok && len(v.([]any)) > 0 && v.([]any)[0] != nil {
		input.Timeout = expandJobTimeout(v.([]any)[0].(map[string]any))
	}

	output, err := conn.RegisterJobDefinition(ctx, input)

	if err != nil {
		return sdkdiag.AppendErrorf(diags, "creating Batch Job Definition (%s): %s", name, err)
	}

	d.SetId(aws.ToString(output.JobDefinitionArn))

	return append(diags, resourceJobDefinitionRead(ctx, d, meta)...)
}
