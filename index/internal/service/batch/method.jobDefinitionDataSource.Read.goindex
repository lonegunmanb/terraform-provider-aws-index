package github.com/hashicorp/terraform-provider-aws/internal/service/batch
import (
	"context"
	"fmt"
	"slices"
	"strings"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/service/batch"
	awstypes "github.com/aws/aws-sdk-go-v2/service/batch/types"
	"github.com/hashicorp/terraform-plugin-framework-validators/resourcevalidator"
	"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator"
	"github.com/hashicorp/terraform-plugin-framework/attr"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-provider-aws/internal/framework"
	fwflex "github.com/hashicorp/terraform-provider-aws/internal/framework/flex"
	fwtypes "github.com/hashicorp/terraform-provider-aws/internal/framework/types"
	tftags "github.com/hashicorp/terraform-provider-aws/internal/tags"
	"github.com/hashicorp/terraform-provider-aws/internal/tfresource"
	"github.com/hashicorp/terraform-provider-aws/names"
)
func (d *jobDefinitionDataSource) Read(ctx context.Context, request datasource.ReadRequest, response *datasource.ReadResponse) {
	var data jobDefinitionDataSourceModel
	response.Diagnostics.Append(request.Config.Get(ctx, &data)...)
	if response.Diagnostics.HasError() {
		return
	}

	conn := d.Meta().BatchClient(ctx)

	var jd *awstypes.JobDefinition

	if !data.JobDefinitionARN.IsNull() {
		arn := data.JobDefinitionARN.ValueString()
		input := &batch.DescribeJobDefinitionsInput{
			JobDefinitions: []string{arn},
		}

		output, err := findJobDefinition(ctx, conn, input)

		if err != nil {
			response.Diagnostics.AddError(fmt.Sprintf("reading Batch Job Definition (%s)", arn), err.Error())

			return
		}

		jd = output
	} else if !data.JobDefinitionName.IsNull() {
		name := data.JobDefinitionName.ValueString()
		status := jobDefinitionStatusActive
		if !data.Status.IsNull() {
			status = data.Status.ValueString()
		}
		input := &batch.DescribeJobDefinitionsInput{
			JobDefinitionName: aws.String(name),
			Status:            aws.String(status),
		}

		output, err := findJobDefinitions(ctx, conn, input)

		if len(output) == 0 {
			err = tfresource.NewEmptyResultError(input)
		}

		if err != nil {
			response.Diagnostics.AddError(fmt.Sprintf("reading Batch Job Definitions (%s/%s)", name, status), err.Error())

			return
		}

		if data.Revision.IsNull() {
			// Sort in descending revision order.
			slices.SortFunc(output, func(a, b awstypes.JobDefinition) int {
				return int(aws.ToInt32(b.Revision) - aws.ToInt32(a.Revision))
			})

			jd = &output[0]
		} else {
			revision := int32(data.Revision.ValueInt64())
			i := slices.IndexFunc(output, func(v awstypes.JobDefinition) bool {
				return aws.ToInt32(v.Revision) == revision
			})

			if i == -1 {
				response.Diagnostics.AddError(fmt.Sprintf("reading Batch Job Definition (%s/%s) revision (%d)", name, status, revision), tfresource.NewEmptyResultError(input).Error())

				return
			}

			jd = &output[i]
		}
	}

	response.Diagnostics.Append(fwflex.Flatten(ctx, jd, &data)...)
	if response.Diagnostics.HasError() {
		return
	}

	arnPrefix := strings.TrimSuffix(aws.ToString(jd.JobDefinitionArn), fmt.Sprintf(":%d", aws.ToInt32(jd.Revision)))
	data.ARNPrefix = types.StringValue(arnPrefix)

	setTagsOut(ctx, jd.Tags)

	response.Diagnostics.Append(response.State.Set(ctx, &data)...)
}
