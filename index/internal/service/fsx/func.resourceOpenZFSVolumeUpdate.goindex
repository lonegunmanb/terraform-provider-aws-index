package github.com/hashicorp/terraform-provider-aws/internal/service/fsx
import (
	"context"
	"log"
	"time"

	"github.com/YakDriver/regexache"
	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/service/fsx"
	awstypes "github.com/aws/aws-sdk-go-v2/service/fsx/types"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/id"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	"github.com/hashicorp/terraform-provider-aws/internal/conns"
	"github.com/hashicorp/terraform-provider-aws/internal/enum"
	"github.com/hashicorp/terraform-provider-aws/internal/errs"
	"github.com/hashicorp/terraform-provider-aws/internal/errs/sdkdiag"
	"github.com/hashicorp/terraform-provider-aws/internal/flex"
	"github.com/hashicorp/terraform-provider-aws/internal/retry"
	tftags "github.com/hashicorp/terraform-provider-aws/internal/tags"
	"github.com/hashicorp/terraform-provider-aws/internal/tfresource"
	"github.com/hashicorp/terraform-provider-aws/internal/verify"
	"github.com/hashicorp/terraform-provider-aws/names"
)
func resourceOpenZFSVolumeUpdate(ctx context.Context, d *schema.ResourceData, meta any) diag.Diagnostics {
	var diags diag.Diagnostics
	conn := meta.(*conns.AWSClient).FSxClient(ctx)

	if d.HasChangesExcept(names.AttrTags, names.AttrTagsAll) {
		openzfsConfig := &awstypes.UpdateOpenZFSVolumeConfiguration{}

		if d.HasChange("data_compression_type") {
			openzfsConfig.DataCompressionType = awstypes.OpenZFSDataCompressionType(d.Get("data_compression_type").(string))
		}

		if d.HasChange("nfs_exports") {
			openzfsConfig.NfsExports = expandOpenZFSNfsExports(d.Get("nfs_exports").([]any))
		}

		if d.HasChange("read_only") {
			openzfsConfig.ReadOnly = aws.Bool(d.Get("read_only").(bool))
		}

		if d.HasChange("record_size_kib") {
			openzfsConfig.RecordSizeKiB = aws.Int32(int32(d.Get("record_size_kib").(int)))
		}

		if d.HasChange("storage_capacity_quota_gib") {
			openzfsConfig.StorageCapacityQuotaGiB = aws.Int32(int32(d.Get("storage_capacity_quota_gib").(int)))
		}

		if d.HasChange("storage_capacity_reservation_gib") {
			openzfsConfig.StorageCapacityReservationGiB = aws.Int32(int32(d.Get("storage_capacity_reservation_gib").(int)))
		}

		if d.HasChange("user_and_group_quotas") {
			openzfsConfig.UserAndGroupQuotas = expandOpenZFSUserOrGroupQuotas(d.Get("user_and_group_quotas").(*schema.Set).List())
		}

		input := &fsx.UpdateVolumeInput{
			ClientRequestToken:   aws.String(id.UniqueId()),
			OpenZFSConfiguration: openzfsConfig,
			VolumeId:             aws.String(d.Id()),
		}

		if d.HasChange(names.AttrName) {
			input.Name = aws.String(d.Get(names.AttrName).(string))
		}

		startTime := time.Now()
		_, err := conn.UpdateVolume(ctx, input)

		if err != nil {
			return sdkdiag.AppendErrorf(diags, "updating FSx for OpenZFS Volume (%s): %s", d.Id(), err)
		}

		if _, err := waitVolumeUpdated(ctx, conn, d.Id(), startTime, d.Timeout(schema.TimeoutUpdate)); err != nil {
			return sdkdiag.AppendErrorf(diags, "waiting for FSx for OpenZFS Volume (%s) update: %s", d.Id(), err)
		}

		if _, err := waitVolumeAdministrativeActionCompleted(ctx, conn, d.Id(), awstypes.AdministrativeActionTypeVolumeUpdate, d.Timeout(schema.TimeoutUpdate)); err != nil {
			return sdkdiag.AppendErrorf(diags, "waiting for FSx for OpenZFS Volume (%s) administrative action (%s) complete: %s", d.Id(), awstypes.AdministrativeActionTypeVolumeUpdate, err)
		}
	}

	return append(diags, resourceOpenZFSVolumeRead(ctx, d, meta)...)
}
